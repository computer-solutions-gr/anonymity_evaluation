{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "# import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "import pandas\n",
    "# %matplotlib inline\n",
    "# plt.rcParams['figure.figsize'] = (16.0, 4.0)\n",
    "# sns.set_style(\"whitegrid\")\n",
    "random_state = 7\n",
    "numpy.random.seed(random_state)\n",
    "from lib.cox_helpers import initialize_cox_store\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AGE</th>\n",
       "      <th>SEX_F</th>\n",
       "      <th>SEX_M</th>\n",
       "      <th>CURADM_DAYS</th>\n",
       "      <th>OUTCOME_H</th>\n",
       "      <th>OUTCOME_N</th>\n",
       "      <th>OUTCOME_I</th>\n",
       "      <th>OUTCOME_D</th>\n",
       "      <th>CURRICU_FLAG</th>\n",
       "      <th>PREVADM_NO</th>\n",
       "      <th>PREVADM_DAYS</th>\n",
       "      <th>PREVICU_DAYS</th>\n",
       "      <th>READMISSION_30_DAYS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>77.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>68.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>83.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    AGE  SEX_F  SEX_M  CURADM_DAYS  OUTCOME_H  OUTCOME_N  OUTCOME_I  \\\n",
       "0  62.0      1      0            1          0          1          0   \n",
       "1  24.0      0      1            2          0          0          1   \n",
       "2  77.0      0      1            2          0          0          1   \n",
       "3  68.0      0      1            7          0          0          1   \n",
       "4  83.0      0      1            2          0          0          1   \n",
       "\n",
       "   OUTCOME_D  CURRICU_FLAG  PREVADM_NO  PREVADM_DAYS  PREVICU_DAYS  \\\n",
       "0          0             0           0             0             0   \n",
       "1          0             0           0             0             0   \n",
       "2          0             0           2             2             0   \n",
       "3          0             0           2             2             0   \n",
       "4          0             0           1             1             0   \n",
       "\n",
       "   READMISSION_30_DAYS  \n",
       "0                    1  \n",
       "1                    0  \n",
       "2                    0  \n",
       "3                    0  \n",
       "4                    0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pandas.read_csv('data.csv', index_col=[0])\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import model_selection\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, roc_auc_score, matthews_corrcoef, accuracy_score\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44384\n",
      "READMISSION_30_DAYS\n",
      "1    22192\n",
      "0    22192\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "zero_indices = data[data['READMISSION_30_DAYS'] == 0].index\n",
    "\n",
    "sample_size_to_remove = sum(data['READMISSION_30_DAYS'] == 0) - sum(data['READMISSION_30_DAYS'] == 1)\n",
    "random_indices = numpy.random.choice(zero_indices, sample_size_to_remove, replace=False)\n",
    "data = data.drop(random_indices)\n",
    "print(len(data))\n",
    "readmission_count = data.groupby('READMISSION_30_DAYS').size().sort_values(ascending=False)\n",
    "print(readmission_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = data.values\n",
    "numpy.random.shuffle(dataset)\n",
    "# split into input (X) and output (Y) variables\n",
    "X = dataset[:,0:12].astype(float)\n",
    "Y = dataset[:,12]\n",
    "# X,Y\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_size = 0.1\n",
    "X_train, X_test, Y_train, Y_test = model_selection.train_test_split(X, Y, test_size=test_size, random_state=7)\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "scaler = scaler.fit(X_train)\n",
    "\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import floor\n",
    "def partition(vector, fold, k):\n",
    "\n",
    "    size = vector.shape[0]\n",
    "\n",
    "    start = floor((size/k)*fold)\n",
    "\n",
    "    end = floor((size/k)*(fold+1))\n",
    "\n",
    "    validation = vector[start:end]\n",
    "    \n",
    "    #print(str(type(vector)))\n",
    "\n",
    "    if str(type(vector)) == \"<class 'scipy.sparse.csr.csr_matrix'>\":\n",
    "\n",
    "        indices = range(start, end)\n",
    "\n",
    "        mask = numpy.ones(vector.shape[0], dtype=bool)\n",
    "\n",
    "        mask[indices] = False\n",
    "\n",
    "        training = vector[mask]\n",
    "\n",
    "    elif str(type(vector)) == \"<class 'numpy.ndarray'>\":\n",
    "        \n",
    "        training = numpy.concatenate((vector[:start], vector[end:]))\n",
    "\n",
    "    return training, validation\n",
    "\n",
    "\n",
    "\n",
    "def Cross_Validation(learner, k, examples, labels):\n",
    "\n",
    "    train_folds_score = []\n",
    "\n",
    "    validation_folds_score = []\n",
    "    \n",
    "    test_score_auc = []\n",
    "    \n",
    "    test_score_mcc = []\n",
    "\n",
    "    for fold in range(0, k):\n",
    "\n",
    "        training_set, validation_set = partition(examples, fold, k)\n",
    "\n",
    "        training_labels, validation_labels = partition(labels, fold, k)\n",
    "\n",
    "        learner.fit(training_set, training_labels)\n",
    "\n",
    "        training_predicted = learner.predict(training_set)\n",
    "\n",
    "        validation_predicted = learner.predict(validation_set)\n",
    "\n",
    "        # print(training_predicted, validation_predicted)\n",
    "        \n",
    "        test_predicted = learner.predict(X_test)\n",
    "\n",
    "        train_folds_score.append(roc_auc_score(training_labels, training_predicted))\n",
    "\n",
    "        # print(training_labels, training_predicted)\n",
    "        # print(numpy.sum(training_labels), numpy.sum(training_predicted))\n",
    "        # print(classification_report(training_labels, training_predicted))\n",
    "\n",
    "        validation_folds_score.append(roc_auc_score(validation_labels, validation_predicted))\n",
    "        \n",
    "        test_score_auc.append(roc_auc_score(Y_test, test_predicted))\n",
    "        \n",
    "        test_score_mcc.append(matthews_corrcoef(Y_test, test_predicted))\n",
    "\n",
    "    return train_folds_score, validation_folds_score, test_score_auc, test_score_mcc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(model, features, labels) :\n",
    "    \n",
    "    cox_store = initialize_cox_store()\n",
    "    cox_store['experiments'].update_row({\n",
    "                    'k': 1,\n",
    "                    'random_state': random_state,\n",
    "                    'start_time': datetime.datetime.now().strftime('%Y%m%d%H%M%S'),\n",
    "                    'classifier': model.__str__().split(\"(\")[0],\n",
    "                    'classifier_full': model.__str__()\n",
    "                })\n",
    "    train_scores, validation_scores, test_scores_auc, test_scores_mcc = Cross_Validation(model, 10, features, labels)\n",
    "    #print(train_scores, validation_scores, test_scores)\n",
    "    print(model)\n",
    "    print('Train AUC', float(format(numpy.mean(train_scores), '.3f')))\n",
    "    print('Validation AUC',float(format(numpy.mean(validation_scores), '.3f')))\n",
    "    print('Test AUC',float(format(numpy.mean(test_scores_auc), '.3f')))\n",
    "    print('Test MCC',float(format(numpy.mean(test_scores_mcc), '.3f')))\n",
    "    print()\n",
    "    cox_store['experiments'].update_row({\n",
    "                    'Train AUC': float(format(numpy.mean(train_scores), '.3f')),\n",
    "                    'Validation AUC': float(format(numpy.mean(validation_scores), '.3f')),\n",
    "                    'Test AUC': float(format(numpy.mean(test_scores_auc), '.3f')),\n",
    "                    'Test MCC': float(format(numpy.mean(test_scores_mcc), '.3f'))\n",
    "    })\n",
    "                                      \n",
    "    cox_store['experiments'].flush_row()\n",
    "    cox_store.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging in: C:\\code\\python\\anonymity_evaluation\\cox\\2f47921a-aeba-4d71-b498-b9a6710bceb8\n",
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
      "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
      "                   random_state=None, solver='liblinear', tol=0.0001, verbose=0,\n",
      "                   warm_start=False)\n",
      "Train AUC 0.723\n",
      "Validation AUC 0.723\n",
      "Test AUC 0.723\n",
      "Test MCC 0.456\n",
      "\n",
      "Logging in: C:\\code\\python\\anonymity_evaluation\\cox\\b99829a3-8ccd-406a-83d5-f46be0ca1683\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "                     metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
      "                     weights='uniform')\n",
      "Train AUC 0.793\n",
      "Validation AUC 0.712\n",
      "Test AUC 0.785\n",
      "Test MCC 0.57\n",
      "\n",
      "Logging in: C:\\code\\python\\anonymity_evaluation\\cox\\25bcbfe1-fd38-4834-92ca-106f297c7547\n",
      "GaussianNB(priors=None, var_smoothing=1e-09)\n",
      "Train AUC 0.708\n",
      "Validation AUC 0.708\n",
      "Test AUC 0.708\n",
      "Test MCC 0.431\n",
      "\n",
      "Logging in: C:\\code\\python\\anonymity_evaluation\\cox\\23239e4f-d5f2-4716-973f-1baff69caf15\n",
      "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
      "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "    tol=0.001, verbose=False)\n",
      "Train AUC 0.711\n",
      "Validation AUC 0.711\n",
      "Test AUC 0.711\n",
      "Test MCC 0.437\n",
      "\n",
      "Wall time: 18 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "models = [LogisticRegression(solver='liblinear'), KNeighborsClassifier(), GaussianNB(), SVC(gamma='auto')] #LogisticRegression(solver='liblinear')\n",
    "for model in models:\n",
    "    run(model, X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00, 38.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   k  random_state  Train AUC  Validation AUC  Test AUC  Test MCC      start_time            classifier                                    classifier_full                                exp_id\n",
      "0  1             7      0.711           0.711     0.711     0.437  20200213155611                   SVC  SVC(C=1.0, cache_size=200, class_weight=None, ...  23239e4f-d5f2-4716-973f-1baff69caf15\n",
      "0  1             7      0.708           0.708     0.708     0.431  20200213155611            GaussianNB       GaussianNB(priors=None, var_smoothing=1e-09)  25bcbfe1-fd38-4834-92ca-106f297c7547\n",
      "0  1             7      0.723           0.723     0.723     0.456  20200213155604    LogisticRegression  LogisticRegression(C=1.0, class_weight=None, d...  2f47921a-aeba-4d71-b498-b9a6710bceb8\n",
      "0  1             7      0.793           0.712     0.785     0.570  20200213155605  KNeighborsClassifier  KNeighborsClassifier(algorithm='auto', leaf_si...  b99829a3-8ccd-406a-83d5-f46be0ca1683"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from cox.readers import CollectionReader\n",
    "\n",
    "reader = CollectionReader('cox')\n",
    "a = reader.df('experiments')\n",
    "\n",
    "print(a.to_string())\n",
    "a.to_excel('experimentalResults.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.4 64-bit ('medibrain': conda)",
   "language": "python",
   "name": "python37464bitmedibrainconda26a62581bc9d4febb30e1b929fdf8fbe"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
